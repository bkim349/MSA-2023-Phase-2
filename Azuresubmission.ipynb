{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA 2023 Phase 2 - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I followed the original/previous exemplar but struggled with creating the virtual environment/Docker container.\n",
    "I have found more success but have pretty much used all of the original code from the exemplar.\n",
    "However, I have used a regressor instead of a classifier to add in some originality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Machine Learning SDK core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Scikit-learn and others\n",
    "from sklearn import datasets; iris = datasets.load_iris()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "#for later\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the workspace for model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path=\"config.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering model onto Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model lr_model\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(ws, model_name=\"lr_model\", model_path=\"lr_model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry Script"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My entry script has been altered to accomdodate a regrssor instead of a classifier. I assumed that the input data as a csv, and had to make a dataframe instead of a numpy array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and share endpoint for marking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To introduce a new dataset, the input data needs to follow these steps:\n",
    "1. Add in 'import pandas as pd' to import the pandas library.\n",
    "2. The data must be introduced into a dataframe: df = pd.read_csv(raw_dataset)\n",
    "3. The dataset must be converted into a dictionary object to be JSON serializable. Use the Dataframe.to_dict() function:  dict_df = df.to_dict()\n",
    "4. The dictionary object created must be an argument for json.dumps():     str.encode(json.dumps(dictionary_object))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('changed_exam_scores.csv',index_col=0)\n",
    "data = df.to_dict()                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wlgoi\n",
    "    data = json.loads(request)\n",
    "    data = np.array(data[\"data\"])\n",
    "    result = model.predict(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('changed_exam_scores.csv',index_col=0)\n",
    "npa = np.array(df)\n",
    "d1 = npa.tolist() \n",
    "data = {'data': d1}\n",
    "body = str.encode(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request failed with status code: 424\n",
      "server: azureml-frontdoor\n",
      "date: Wed, 09 Aug 2023 09:56:52 GMT\n",
      "content-type: application/json\n",
      "content-length: 83\n",
      "x-ms-run-function-failed: False\n",
      "x-ms-server-version: azmlinfsrv/0.8.4\n",
      "x-ms-request-id: 1d53da34-b71a-44ea-bc16-922441e8c6f8\n",
      "x-request-id: 1d53da34-b71a-44ea-bc16-922441e8c6f8\n",
      "ms-azureml-model-error-reason: model_error\n",
      "ms-azureml-model-error-statuscode: 500\n",
      "azureml-model-deployment: lr-model-1\n",
      "connection: close\n",
      "\n",
      "\n",
      "{\"message\": \"An unexpected internal error occurred. Check the logs for more info.\"}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "df = pd.read_csv('changed_exam_scores.csv',index_col=0)\n",
    "npa = np.array(df)\n",
    "d1 = npa.tolist() \n",
    "data = {'data': d1}\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'https://msa2023-phase2-azure-xswgk.australiaeast.inference.ml.azure.com/score'\n",
    "# Replace this with the primary/secondary key or AMLToken for the endpoint\n",
    "api_key = ''\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'lr-model-1' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please do not delete or turn off any resources until the MSA team has completed marking. Once finished marking, this will be announced on Discord, after which (to avoid incurring unnecessary costs):\n",
    "1. Delete your models and endpoints from [Machine Learning Studio](https://ml.azure.com/).\n",
    "1. Delete or turn off any resources you created, as explained in [this section](https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-azure-ml-in-a-day?view=azureml-api-2#delete-all-resources) of the Azure Machine Learning documentation."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdb671202a387ebf0bc7bf04476cbafa528fae566193c2efe94e2aaf8539be45"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
